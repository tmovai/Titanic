{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv ('data/titanic_train_master.csv')\n",
    "test = pd.read_csv ('data/titanic_test_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined all data for feature creation\n",
    "# this removes potential for dummies in one set and not the other\n",
    "train_end_row = train.shape[0]\n",
    "test_end_row = test.shape[0]\n",
    "combined = pd.concat ([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case all column names\n",
    "combined.columns = map (str.lower, combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies function to create binary columns for groups\n",
    "def create_dummies (df, column_names):\n",
    "    for col in column_names:\n",
    "        dummies = pd.get_dummies (df[col], prefix=col)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try combining Pclass + Sex\n",
    "combined['psex'] = combined['pclass'] + combined['sex'].map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCLASS\n",
    "combined = create_dummies (combined, ['pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract titles from name\n",
    "titles = {\n",
    "    \"Mr\" :         \"mr\",\n",
    "    \"Mme\":         \"mme\",\n",
    "    \"Ms\":          \"mme\",\n",
    "    \"Mrs\" :        \"mrs\",\n",
    "    \"Master\" :     \"master\",\n",
    "    \"Mlle\":        \"miss\",\n",
    "    \"Miss\" :       \"miss\",\n",
    "    \"Capt\":        \"officer\",\n",
    "    \"Col\":         \"officer\",\n",
    "    \"Major\":       \"officer\",\n",
    "    \"Dr\":          \"officer\",\n",
    "    \"Rev\":         \"officer\",\n",
    "    \"Jonkheer\":    \"royalty_male\",\n",
    "    \"Don\":         \"royalty_male\",\n",
    "    \"Sir\" :        \"royalty_male\",\n",
    "    \"Countess\":    \"royalty_female\",\n",
    "    \"Dona\":        \"royalty_female\",\n",
    "    \"Lady\" :       \"royalty_female\"\n",
    "}\n",
    "extracted_titles = combined['name'].str.extract (' ([A-Za-z]+)\\.', expand=False)\n",
    "combined['title'] = extracted_titles.map(titles)\n",
    "\n",
    "# create dummies for titles\n",
    "combined = create_dummies (combined, ['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEX\n",
    "# train['sex'] = train['sex'].map({'male':0, 'female':1}) \n",
    "# test['sex'] = test['sex'].map({'male':0, 'female':1})\n",
    "combined = create_dummies (combined, ['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE\n",
    "# if title_master is true and age is null set age to 1. Then group ages. \n",
    "# Trying to save some rows\n",
    "def set_age (row):\n",
    "    if row['title_master'] & pd.isnull(row['age']):\n",
    "        return 1\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "combined['age'] = combined.apply (lambda row: set_age(row), axis=1)\n",
    "\n",
    "# create age groups.\n",
    "def create_groups_dummies (df, col, cat_name, cut_points, label_names):\n",
    "    df[col] = df[col].fillna(-0.5)\n",
    "    df[cat_name] = pd.cut (df[col], cut_points, labels=label_names)\n",
    "    df = create_dummies (df, [cat_name])\n",
    "    return df\n",
    "\n",
    "age_cut_points = [-1, 0, 12, 18, 40, 60, 100]\n",
    "age_group_labels = ['missing', 'child', 'teenager', 'young_adult', 'adult', 'senior']\n",
    "\n",
    "combined = create_groups_dummies (combined, 'age', 'age_cat', age_cut_points, \n",
    "                                    age_group_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAMILY feature\n",
    "# This will capture sibsp and parch so they can be dropped\n",
    "combined['family'] = combined['sibsp'] + combined['parch'] + 1\n",
    "combined = create_dummies (combined, ['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICKET\n",
    "# Extract ticket number and then assume all with the same number are traveling together\n",
    "ticket_split = combined['ticket'].str[::-1].str.split(' ', 1, expand=True)\n",
    "combined['ticketnum'] = ticket_split[0].str[::-1]\n",
    "combined['ticketnum'] = combined['ticketnum'].str.replace(\"LINE\", '0')\n",
    "combined['ticketnum'] = combined['ticketnum'].apply(pd.to_numeric)\n",
    "# fam_groups = combined['ticketnum'].value_counts()\n",
    "combined['ticket_group'] = 0\n",
    "tgroup = {}\n",
    "groupnum = 0\n",
    "for i, row in combined.iterrows():\n",
    "    ticketnum = row['ticketnum']\n",
    "    if ticketnum in tgroup and (row['title_master'] or row['sex_female']):\n",
    "        combined.at[i, 'ticket_group'] = tgroup[ticketnum]\n",
    "    else:\n",
    "        tgroup[ticketnum] = groupnum\n",
    "        combined.at[i, 'ticket_group'] = groupnum\n",
    "        groupnum += 1\n",
    "combined.drop(['ticketnum'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     passengerid  survived  pclass                name   sex   age  sibsp  \\\n152         1044       NaN       3  Storey, Mr. Thomas  male  60.5      0   \n\n     parch ticket  fare  ... family_1 family_2  family_3  family_4  family_5  \\\n152      0   3701   NaN  ...        1        0         0         0         0   \n\n     family_6 family_7  family_8  family_11  ticket_group  \n152         0        0         0          0           878  \n\n[1 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passengerid</th>\n      <th>survived</th>\n      <th>pclass</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>...</th>\n      <th>family_1</th>\n      <th>family_2</th>\n      <th>family_3</th>\n      <th>family_4</th>\n      <th>family_5</th>\n      <th>family_6</th>\n      <th>family_7</th>\n      <th>family_8</th>\n      <th>family_11</th>\n      <th>ticket_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>152</th>\n      <td>1044</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Storey, Mr. Thomas</td>\n      <td>male</td>\n      <td>60.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3701</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>878</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 45 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# FARE\n",
    "# Find the one null rec and see if we can fill it\n",
    "combined.loc[combined['fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one nan can be filled with the average for the passenger\n",
    "filler = combined.loc[(combined['pclass']==3) & \n",
    "                        (combined['sex']==\"male\") & \n",
    "                        (combined['age']>55) & \n",
    "                        (combined['age']<65)]['fare'].dropna().mean()\n",
    "combined['fare'] = combined['fare'].fillna(filler)\n",
    "fare_group_labels = ['missing', '0-12', '12-50', '50-100', '100+']\n",
    "fare_cut_points = [-1, 0, 12, 50, 100, 1000]\n",
    "# fare_cut_points = [-1, 0, 172, 342, 1000]\n",
    "combined = create_groups_dummies (combined, 'fare', 'fare_cat', \n",
    "                                fare_cut_points, fare_group_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CABIN\n",
    "combined['cabin_type'] = combined['cabin'].astype(str).str[0]\n",
    "combined = create_dummies (combined, ['cabin_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBARKED \n",
    "# fill empties with the most frequent\n",
    "# C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "most_frequent = combined['embarked'].value_counts().index[0]\n",
    "combined['embarked'] = combined['embarked'].fillna(most_frequent)\n",
    "combined = create_dummies (combined, ['embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "combined.drop(['pclass', 'name', 'ticket', 'title', 'sex', 'age', 'family', 'sibsp', 'parch', 'embarked', 'cabin', 'fare', 'fare_cat', 'cabin_type', 'age_cat'], 1, inplace=True)\n",
    "combined.columns = map (str.lower, combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split back into train and test. Drop survived from test\n",
    "train_final = combined.iloc[:train_end_row]\n",
    "test_final = combined.iloc[train_end_row:].drop(['survived'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out final files\n",
    "train_final.to_csv ('data/titanic_train_wrangled.csv', index=False)\n",
    "test_final.to_csv ('data/titanic_test_wrangled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 0 to 890\nData columns (total 49 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   passengerid           891 non-null    int64  \n 1   survived              891 non-null    float64\n 2   psex                  891 non-null    int64  \n 3   pclass_1              891 non-null    uint8  \n 4   pclass_2              891 non-null    uint8  \n 5   pclass_3              891 non-null    uint8  \n 6   title_master          891 non-null    uint8  \n 7   title_miss            891 non-null    uint8  \n 8   title_mme             891 non-null    uint8  \n 9   title_mr              891 non-null    uint8  \n 10  title_mrs             891 non-null    uint8  \n 11  title_officer         891 non-null    uint8  \n 12  title_royalty_female  891 non-null    uint8  \n 13  title_royalty_male    891 non-null    uint8  \n 14  sex_female            891 non-null    uint8  \n 15  sex_male              891 non-null    uint8  \n 16  age_cat_missing       891 non-null    uint8  \n 17  age_cat_child         891 non-null    uint8  \n 18  age_cat_teenager      891 non-null    uint8  \n 19  age_cat_young_adult   891 non-null    uint8  \n 20  age_cat_adult         891 non-null    uint8  \n 21  age_cat_senior        891 non-null    uint8  \n 22  family_1              891 non-null    uint8  \n 23  family_2              891 non-null    uint8  \n 24  family_3              891 non-null    uint8  \n 25  family_4              891 non-null    uint8  \n 26  family_5              891 non-null    uint8  \n 27  family_6              891 non-null    uint8  \n 28  family_7              891 non-null    uint8  \n 29  family_8              891 non-null    uint8  \n 30  family_11             891 non-null    uint8  \n 31  ticket_group          891 non-null    int64  \n 32  fare_cat_missing      891 non-null    uint8  \n 33  fare_cat_0-12         891 non-null    uint8  \n 34  fare_cat_12-50        891 non-null    uint8  \n 35  fare_cat_50-100       891 non-null    uint8  \n 36  fare_cat_100+         891 non-null    uint8  \n 37  cabin_type_a          891 non-null    uint8  \n 38  cabin_type_b          891 non-null    uint8  \n 39  cabin_type_c          891 non-null    uint8  \n 40  cabin_type_d          891 non-null    uint8  \n 41  cabin_type_e          891 non-null    uint8  \n 42  cabin_type_f          891 non-null    uint8  \n 43  cabin_type_g          891 non-null    uint8  \n 44  cabin_type_t          891 non-null    uint8  \n 45  cabin_type_n          891 non-null    uint8  \n 46  embarked_c            891 non-null    uint8  \n 47  embarked_q            891 non-null    uint8  \n 48  embarked_s            891 non-null    uint8  \ndtypes: float64(1), int64(3), uint8(45)\nmemory usage: 74.0 KB\n"
    }
   ],
   "source": [
    "train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}